# TA零散知识

知识非常杂。

早期的笔记（比较靠前）看上去比较稚嫩，很多类似常识的东西都记下来了。。。

修复中。。。

2023.6.9 Part1修复完毕



---



# AO-Ambient Occlusion-环境光遮蔽

如果两个物体靠的很近，比如我的手臂和身体的一侧，它们比较靠近的地方其实会偏暗。

渲染中的漫反射（以PBR为例），物体的漫反射分为直接光源和间接光源两个部分，**直接光源部分会受到遮挡的影响**，但是**间接光源部分不会**，因为其值会直接由法线半球对Cube Map或球谐函数采样获得，所以**无法计算遮挡**，这会导致本来稍暗的地方会偏亮。

为了模拟正确的效果，会使用AO。目前的做法可以理解为：先通过DCC（如SP）烘培出AO贴图，再通过uv对AO贴图采样，**通过得值乘以漫反射的强度**来造成影响。

AO贴图常常是灰度图，**白色代表无遮蔽，黑色代表完全遮蔽**。

关于AO在后来的学习中遇到了很多：

查阅：[百人计划笔记 ：SSAO](../百人计划学习笔记/百人计划学习笔记.md#61：SSAO)

GAMES 202 —— SSAO：

> 和之前的3D空间下的计算区分开来，之前的叫“图像空间”（Image  Space）。屏幕空间下的处理就基本是后处理了，输入是若干图，输出最终图。      关于AO、之前在零散知识积累中记过一些，但其实想来根本没有那么复杂。记得在入门精要中提到的标准光照模型中，有一项Ambient项，代表环境光，在那里这个项就是一个定值。但是为了模拟环境光遮蔽的效果，其实可以在Ambient项上做一个遮罩，使有的地方环境光亮、有的地方则暗，使得其立体感更强。     AO的原理就是对于每一个渲染点，我计算它在法线半球的可见性的Cos加权的平均，最终得到一个0~1的值代表环境光强度，把这个保存到贴图上即是AO贴图，和一个遮罩很像。     如何基于屏幕空间来做？     1.首先，根据屏幕空间的像素位置和深度（所以需要渲染深度图）可以构建一个三维坐标，作为这个渲染点的位置。     2.以这个渲染点为中心、记录的法线方向（所以还需要渲染法线方向图）为方向构建一个半球，半径自己指定。     3.向半球中随机撒点，通过点的z值和记录的深度图的z值可以判断这个点对于相机是否可见。简单判断是否可见往往会导致不该出现AO的地方也有AO，因为遮挡物可能离渲染点非常远。所以这里也可以加上一个判断，若二者深度相差太多则不算遮挡。     4.用Cos a（a为点到球心的连线与法线的夹角）加权平均洒下的各点的可见性，即可得到大概的环境光的强度值。     5.最终应该渲出一张灰度图，把它叠加到原渲染纹理中去即是最终结果。



---



# 在Shader中使用结构体

在学习NPR的时候，我参考了大佬写的Shader。

这个Shader在结构体的使用上做得非常美观合理，我认为非常具有参考价值。

如果自己做一些比较大的Shader时，也使用这种方法吧。

参考文章：[罪恶装备](https://zhuanlan.zhihu.com/p/493802718)

![img](Images/clip_image004.png)    ![img](Images/clip_image005.png) ![img](Images/clip_image006.png) 



---



# 编辑Shader的材质面板



## **使用属性标签（约束、Attribute）来简易地编辑Shader的材质面板**

[参考](https://docs.unity3d.com/Manual/SL-Properties.html)

列举一些常用的：

```c#
[Header(MyFloat)]// 加一个标题
[space(20)]// 加一点空隙
_MyFloat("MyFloat",Range(0,1)) = 1.0
```

效果：

![image-20230609144606972](Images/image-20230609144606972.png) 

除了上面这两个能用的，其他的C#能用的这里都不能用，很垃圾。

基本只有下表中的语法能用：

![image-20230609144940594](Images/image-20230609144940594.png)

![image-20230609145000241](Images/image-20230609145000241.png)



## 使用Custom Shader GUI

更**自由**的方式，可以做很多**炫酷**的材质UI。

但是比较**麻烦**，得看值不值得去写这个东西。

[跳转](#关于自定义材质GUI)



---



# 关于GGX

在渲染尤其是**真实感渲染**中，我们总会看到一个词叫**GGX**，它总是和微表面模型等概念一起出现。

> GGX是一种用于描述光学反射和折射**分布的函数**，通常用于计算三维计算机图形中的材质反射和折射。GGX代表Gaussian or Generalized Gaussian distribution的缩写，也称为Trowbridge-Reitz分布。 GGX函数旨在模拟实际材质表面的微观结构，以产生更真实的光照效果。

不可追溯全称，其是一种分布函数，可以参与BRDF的计算，主要体现在**渲染粗糙度大的镜面反射**上，能渲染出更逼真的j页面反射部分。

在202笔记中也出现了GGX，本质上GGX就是一个**类似高斯分布的函数**，但它不是一成不变，它会随着粗糙度变化，**它记录的是相对与面法线，微表面的分布如何（微表面与面法线的对齐程度）**。   

比如PBR中，计算D项（法线分布函数）需要使用微表面模型，自然也使用了GGX来计算微表面分布，不仅如此，在G项（自我遮蔽项）中也参考了GGX的值。     **总结：GGX是一个实时级的分布函数，常用来在微表面模型中计算微表面与视线的对齐程度。在微表面模型的D项、G项中，用来计算观察方向有多少能量反射。因为其作用于DG项，所以其本质仅对镜面反射部分产生影响。**

![img](Images/clip_image013.png)            



![img](Images/clip_image014.png) 



---



# 阴影渲染

列举一些阴影渲染方法：

| 名称                                                    | 说明                                                         | 优点             | 缺点                             |
| ------------------------------------------------------- | ------------------------------------------------------------ | ---------------- | -------------------------------- |
| Shadow  Mapping                                         | 灯光处渲深度，相机渲深度，在正式**渲染渲染点时，比较两个缓冲区中的深度**，判断渲染点是否在阴影下。<br />这只是一种基本的思路，目前没有任何成熟的引擎直接使用这种阴影映射方式。 | 快               | 锯齿重                           |
| SSSM（Screen Space Shadow  Mapping）                    | 对Shadow Mapping做了一些改进，它先渲染灯光处深度，然后在屏幕空间再渲一次深度，**对比两个深度得出一张阴影图**（灰度图，说明该像素的阴影的强度。）<br />在**渲染渲染点时，从阴影图中用屏幕空间坐标采样得到阴影系数**，然后拿去影响颜色就行了。<br />相比传统Shadow Mapping，就是多了一步生成阴影图。 | 快               | 可能有伪影                       |
| PCSS(Percentage Closer Soft Shadows/百分比接近的软阴影) | [详见GAMES202：PCSS](../GAMES202学习笔记/GAMES202学习笔记.md)<br />以滤波核的形式去在比较两个缓冲区中的深度，看有**多少比例被遮挡**，多少比例未被遮挡。通过比**例决定阴影的硬度**。 | 真实，近实远虚   | 比较慢                           |
| VSSM（Variance Soft Shadow Mapping/方差软阴影）         | [详见GAMES202：VSSM](../GAMES202学习笔记/GAMES202学习笔记.md)。<br />其本质是**PCSS的改进**，**基于一些数学算法来对阴影进行估计**，从而减少计算量来加速阴影的计算。 | 较真实且较快     | 容易在高频变化区域出现错误的阴影 |
| MSM（moment shadow mapping/矩阴影映射）                 | [详见GAMES202：MSM](../GAMES202学习笔记/GAMES202学习笔记.md)<br />本质是对**VSSM的改进**，对VSSM中的**“估算”部分增加了计算**，计算复杂，需要较高的数学知识。 | 比VSSM真实       | 比VSSM慢                         |
| DFSS（Distance Field Soft Shadows/距离场软阴影）        | [详见GAMES202：DFSS](../GAMES202学习笔记/GAMES202学习笔记.md)<br />也可以理解为**PCSS的改进**。DFSS从渲染点到光源进行连线，然后寻找这个线上距离场记录的值的最小值，**最小的这个角度的arcSin(theta)就可以作为PCSS中需要的“采样范围内，多少比例的像素被遮挡”的值**。 | 快，且效果很好。 | 保存SDF是很占用空间的。          |

得益于时间域的方法和硬件的加速，PCSS是目前的主流实时渲染阴影的方法。



---



# 关于金属度、粗糙度工作流和镜面反射光泽度工作流

太杂了，在好多地方记了。

这里做一下汇总和修复，同时引用的部分也会被修复。

旧版：

> 目前主流的PBR工作流有**金属粗糙度和镜面反射光泽度两种**，对于AO、法线、自发光等常规贴图，它们的处理完全一致，这里不考虑。
> 金属粗糙度：baseColor贴图（RGB，其中包含了物质的基本颜色和金属的反射率值，反射率即是F0）、金属度贴图（灰度，指定金属度）、粗糙度贴图（灰度，指定粗糙度）
> 优劣：
> 非金属的F0固定为0.04，无法调整；
> 主流的工作流，用途广泛；
>
> 镜面反射光泽度：diffuse（RGB，Diffuse贴图严格影响着材质的基本颜色而对材质的其他特征（如反射率）没有影响。）、镜面反射贴图（RGB，记录金属和非金属的F0）、光泽度贴图（灰度，指定光泽度）
> 优劣：
> 可以对金属、非金属的F0自由调整，但是这也非常容易做出违反能量守恒定律的材质；
> 两张RGB贴图，对性能的要求会更高；
>
> 思考：
> 1.手连PBR是金属粗糙度工作流的，金属度参数用来决定镜面反射受到多少baseColor的影响。
> 2.对于镜面反射光泽度工作流，我猜测镜面反射贴图三维，分别记录两个F0、和类似金属度的值，用来在两个F0中插值。



非常详细，建议看这个

[百人计划笔记：63：metalrough与specgloss流程](../百人计划学习笔记/百人计划学习笔记.md##63：metalrough与specgloss流程)



偏结论向

[关于PBR：](../关于PBR/关于PBR.md)

> **看本质、看代码**
>
> 分析一下代码，“金属度”这个量，作为阿尔法在F0（可以理解为很暗的灰色）和物体本身颜色间插值，得到的值经过计算后作为直接光照的镜面反射部分。也就是说，非金属的镜面反射颜色不太受自身颜色影响，而金属的镜面反射颜色受自身颜色影响大。观察手连PBR，得到相同的结论。

> **粗糙度控制着什么？**
>
> 1.直接光照的镜面反射部分的D项，越粗糙，D项一般越小，代表渲染点的微表面们，和反射方向不太对齐。     
>
> 2.直接光照的镜面反射的G项，越粗糙，自遮蔽现象越重，G项越小。      
>
> 3.间接光照镜面反射第一部分入射光的计算。间接光照镜面反射的光源通过观察方向做反射，再对CubeMap采样确定，但是由于粗糙度不同，其实也需要对不同清晰度的CubeMap采样，这样的效果更真实，此处粗糙度作为参考值，决定采用哪一个层级的CubeMap。越粗糙，使用越模糊的CubeMap。    
>
> 4.间接光照镜面反射第二部分，作为参数之一，和NV一起、参与数值拟合，避免计算积分，越粗糙，一般来说镜面反射越弱。

> **金属度控制着什么？**
>
> 1.直接光照镜面反射部分的F项。金属度作为参考值，对F0（0.04，可视为一个接近黑色的颜色）和物体本身颜色插值，得到的颜色经过计算后作为直接光照镜面反射部分使用。也就是说，非金属的镜面反射颜色不太受自身颜色影响，而金属的镜面反射颜色受自身颜色影响大。观察手连PBR，得到相同的结论。
>
>  2.直接光照漫反射的KD。KD本是1-KS（KS也就是F项）得到，但是KD又做了一步乘（1 -  Metallic），意味着，非金属漫反射强，能量几乎没有吸收，金属漫反射弱，有能量的吸收。     
>
> 3.间接光照的镜面反射的F项，金属度控制F0（指通过金属度在0.04和baseColor插值后得到的颜色），而F0参与F项的计算，产生的影响和1.中一致。



---



# 关于顶点的法线、切线、和副切线

[祖传参考文章](https://zhuanlan.zhihu.com/p/103546030)

经过了平均法线写入工具的开发流程，我更理解了Mesh的顶点是一个怎样的存在，也理解了其实**没有所谓的面法线，只有顶点有**。面法线是DCC自己从顶点通过重心坐标等手段插值算出来的。**顶点携带法线信息**，是三维向量。     

**顶点的切线也是顶点携带的信息**，也是三维向量（Unity中貌似是四维？）。**切线是与法线垂直的线**，因为空间内与法线垂直的线有无数条，所以通过顶点的UV中的V值来确定唯一的一根。     

顶点的**副切线是垂直于上述两条线的线**，副切线有两种可能（上或下），通过v.tangent.w *  unity_WorldTransformParams.w决定，前者与DCC软件有关，后者与模型的Scale的负值的个数有关。**副切线不是顶点携带的信息**，是需要计算才能得到的值。



---



# 为什么法线贴图总呈现蓝紫色

法线扰动向量是xyz三维值,  我们得找个东西来储存它, 用什么来存呢? 

正好, 图片也是rgb3个值, 就用它吧。不过, 法线扰动向量**xyz这3个值的取值范围都是(-1, 1), 而rgb的取值范围是(0, 1), 需要换算一下。**

从x映射到r, 就这样算: **r = (x + 1) / 2**。因为**大多数法线**直指屏幕外、也就是笔直冲上，不扰动，所以: **x=0, y=0, z=1**     对应rgb为: **r=0.5, g=0.5, b=1**     所以法线贴图大多是蓝紫色。

相关扩展：[百人计划笔记：法线贴图为什么记录的是切线空间下的扰动？](../百人计划学习笔记/百人计划学习笔记.md)



---



# 对于深度测试的误解

[百人计划笔记：深度测试](../百人计划学习笔记/百人计划学习笔记.md)——这里有关于深度测试更详细的内容。

之前我一直认为深度测试和深度写入之间有关系，得过了深度测试（怎么算过自己指定）才能指定是否写入深度，但其实不是这样。

其实**深度测试和深度写入是几乎独立的两个东西**。

用户可以指定是否开启深度测试、是否开启深度写入，这两个完全独立。唯一的一点点联系就是，如果片元的深度测试没有通过，这个片元会被直接舍弃，不再进行后续的流程。深度写入作为深度测试后面的一个流程，自然会被直接跳过。

![image-20220925011913289](Images/image-20220925011913289.png) 



---



# 在Shader中获取时间

虽然在入门精要里了解过，但是入门精要的笔记做得实在垃圾，没有写具体方法，而连连看获取时间相对简单，所以一直没有掌握。写理发店Shader的时候，遇到了这个问题，故回顾入门精要，要记住如下用法：

<img src="Images/IMG_20220927_155303_edit_468075674430656.jpg.jpg" alt="IMG_20220927_155303_edit_468075674430656.jpg" style="zoom:67%;" /> 



---



# 在Shader中添加HDR性质的颜色

![image-20220927155507592](Images/image-20220927155507592.png) 



---



# 关于Scriptable Object

~~这不是开发的知识吗？~~

差不多得了，这都不懂还能当TA？😅

## 是什么

是一种资产的类型，类似于配置文件，但是它不仅可以用来保存数据，也可以用来实现函数。它的函数可以在自己写的、针对于它的、Editor的派生类来调用和控制。

## 干什么使的

**用来保存类似“Static”的共用的、不变的数据。**保存于此类资产的数据，不会随着游戏的关闭、重开而改变。比如可以作为配置文件保存敌人的各项数值，在敌人初始化的时候，使用这个资产里的数据，随后把这个控制资源给策划，让策划去调数值。这样不仅可以集中控制，而且可以节省内存，因为实例化后的各物体共用这一块资产内的数据。

**用于资产实现型工具制作。**这一条其实是我在研究插件“Pro Pixelizer”时顺便学习的，作者在插件的子工具中，使用了这种“资产实现型工具”。这种工具的使用流程是：创建工具资产 → 操作资产 →  实现工具功能。而一般的工具是：打开工具面板→操作工具面板 → 实现工具功能。“资产实现型工具”创建资产时，创建的就是Scriptable Object的派生类的对象，而作为工具，仅有保存数据的功能时不够的，需要在Scriptable Object的派生类中实现方法。那如何调用这里面的方法？这需要Editor的派生类的支持，开发者需要自己写一个专用于这种资产的Editor的派生类，然后通过Editor的派生类定义GUI、绑定方法，如此即可。



---



# 关于“资产实现型工具”

这其实是我自定的名字，我也不知道别人叫这种工具叫什么。

根据GPT的总结，这种工具似乎可以称作：

> 在Unity中，基于ScriptableObject类来制作工具的方法被称为“可重用性系统”（Reusable System），也被称为“数据驱动系统”（Data-Driven System）。
>



这种工具的使用流程是：创建工具资产→ 在检查器中操作资产 →  实现工具功能。而一般的工具是：打开工具面板 →操作工具面板 → 实现工具功能。上面稍微提了一下“资产实现型工具”，我现在要说一些细则。

1. 一般Scriptable Object不实现什么方法，但是**“资产实现型工具”的Scriptable Object需要实现大量的方法**。虽然也可以在Scriptable Object里实现工具方法，但那会导致代码有点肿，和普通工具一样了，GUI代码和功能实现代码放在一块。

2. Custom Editor需要申明，这个编辑器针对于哪一种资产。如下代码块：

   ```c#
   //在Editor类申明前，申明它针对于哪一种Scriptable Object，这里SteppedAnimation是一种Scriptable Object
   [CustomEditor(typeof(SteppedAnimation))]
   public class SteppedAnimationEditor : Editor
   ```

3. GUI的虚函数不再覆盖”OnGUI“，而是**覆盖”OnInspectorGUI“**。这控制检查器的GUI刷新。

4. 如果不给Scriptable Object写Editor，那么它的public参数会自动序列化，显示在检查器中。但是如果你写了Editor，这将不再是自动的，需要开发者自己写Scriptable Object的参数的显示逻辑，如下：

   ```c#
   //以下两个参数都是原Scriptable Object的public参数，但因为这里使用了Editor，如果不写这个，这两个参数将不再显示。
   EditorGUILayout.PropertyField(serializedObject.FindProperty("SourceClips"));
   EditorGUILayout.PropertyField(serializedObject.FindProperty("KeyframeMode"));
   ```

这种类型的工具相比于具有独立面板的工具，可以把功能实现代码和GUI代码分开，其他积极意义，目前没想明白。

如果将来想要开发“资产实现型工具”，这里写的东西很可能不够用，我把我学习的工具源码保存于此处：[资产实现型工具](../供日后参考/资产实现型工具)（Ctrl + 左键单击访问）



**轻量级的工具也非常适合**使用Scriptable Object进行开发。

实习中开发了一个简易的Unity中的烘培工具，使用资产实现型的思路进行开发，**所有代码都在一个Scriptable Object的派生类中**，**不用额外去写GUI代码**，直接使用序列化默认的UI，很省事。

Odin中有非常多适合ScriptableObject进行工具开发的属性标签，如：

Button、OnValueChanged等等。



---

# 关于自定义材质GUI

虽然默认材质可以自动生成材质GUI，也可以通过Attribute设置一些简单的GUI，但是要更好地客制化，还是需要脚本的支持，Unity也提供了相应的基类供使用。

以下为使用方法和细则：



## 在Shader末尾、同FallBack一起、绑定GUI脚本

```c#
//	通过字符串指定GUI脚本名称来绑定GUI脚本，插件里作者把GUI脚本和Shader放在同文件夹下，因此没有路径信息。如果在不同的文件夹，
//	是否需要路径信息？这一点我真不知道。
CustomEditor "PixelizedWithOutlineShaderGUI"
FallBack "ProPixelizer/Hidden/MyPixelBase"
```



## 细则

1. 继承自ShaderGUI

   ```c#
   public class PixelizedWithOutlineShaderGUI : ShaderGUI
   ```

2. 重写OnGUI函数，和工具面板的OnGUI逻辑几乎一样

   ```c#
   //这两个参数是不能少的，第一个是这个材质的面板对象，用于添加GUI组件等，第二个是Shader的参数数组
   public override void OnGUI(MaterialEditor materialEditor, MaterialProperty[] properties)
   ```

3. 例行性工作，不知道这是不是自动生成的，但是不能少

   ```c#
   //更新面板，普通的工具也需要更新，作为GUI当然是需要频繁刷新的
   materialEditor.serializedObject.Update();
   //获取材质。虽然GUI脚本被绑在Shader上，但其实是没法对Shader操作什么的
   //GUI脚本肯定是基于某个使用了这个Shader的材质更改的
   Material = materialEditor.target as Material;
   ```

4. 陈列属性

   ```c#
   //作为GUI，基本的功能当然是显示并控制Shader的变量。一次变量的绑定过程如下
   var albedo = FindProperty("_Albedo", properties);
   editor.TextureProperty(albedo, "Albedo", true);
   ```



## 日后参考

这个ShaderGUI脚本是少有的，我把它保存下来供日后参考。其中含有完整的流程，也有一些如折叠参数菜单、开关等参数的设定方法，非常有参考价值。

[ShaderGUI](..\供日后参考\ShaderGUI)（Ctrl + 左键单击访问）



---



## 关于软硬边和平滑组

这两个本质上是相同的概念，只是所处的DCC不同，叫法不同，在Maya中，叫做软硬边，在Max中，叫做平滑组，在Houdini中，这一块直接被Normal节点控制着。

在之前“法线平滑工具”的开发中，我了解到，一个点并非只是一个点，一个点连了多少条线（或者说被多少个平面共用），这个位置上就有几个端点（借用Houdini的说法），每个归属于其中一个面。这些端可以拥有不同朝向的法线。

### 关于软硬边

以一个Cube为例，它的一个顶点上，其实有3个端点（这里我们沿用Houdni的叫法）。我们看一条棱，这个棱有两个点、6个端点，每个端点有一个法线，而参与这条棱的两个面的端点，有4个。当这四个端点的法线朝向一致时（就像我用工具做完法线平滑一样），我们认为这是一条软边，当不一致时则认为这是一条硬边。在着色时，着色点的法线方向是靠重心坐标插值出来的，这意味着，如果有软边的参与，则两个相邻面的渲染、他们的交界处必然是平滑的，因为他们相交的边的端点的法线朝向相同。

### 关于平滑组

本质上在做和软硬边相同的事情。平滑组是类似于给面一个属性，如果两个相邻面的平滑组属性的值相同，则它们相交的边的四个端点会使用平滑后的法线（以四边形为例）。

---



## Unity的深度法线纹理

前向渲染中若要用G-Buffer需要在相机勾选生成深度法线纹理，这个深度法线纹理的深度是编码过的、非线性的、0~1的深度值。法线是观察空间的法线方向，也就是模型空间顶点位置乘以M矩阵和V矩阵后的那个坐标的空间，可以理解为，以相机为原点，相机顶为y正，相机朝向为z负方向的坐标系。

---



## URP渲染管线中，多PassShader的Pass执行顺序与执行可能问题

URP渲染管线中，默认不再支持多Pass渲染，但是通过一些特殊的Tag可以做到多Pass渲染。

已一个“先通过一个Pass渲染模板值到缓冲区、再通过另一个pass渲染扩张后的模型到颜色缓冲区”的描边效果为例：

通过给模板值Pass以"LightMode" = "SRPDefaultUnlit"，可以使其先执行。

通过给颜色Pass以"LightMode" = "UniversalForward"，可以使其后执行。

这样可以做到简易的多Pass。与Tag高度相关。

相关理论可以参考一下这篇文章：[知乎](https://zhuanlan.zhihu.com/p/469589277)。

相关落地用法，也可以看下这个：[CSDN](https://blog.csdn.net/zakerhero/article/details/106264067)。

这种方法仅适用于两个Pass，再多就只能用Renderer Feature的方法了。

---



## 关于Layer 和 Render Layer

### 是什么

Layer是物体的一个属性，本质是int型的一个参数。

![image-20221013200939822](Images/image-20221013200939822.png) 

它依附于每一个Game Object。

Render Layer是仅SRP才拥有的、一个FilterSetting的属性，本质也是一个int型的参数 。

![image-20221013201215689](Images/image-20221013201215689.png) 

上句是调用一次Draw Call的函数，参数m_FilteringSettings中，包含了Render Layer。

![image-20221013201356695](Images/image-20221013201356695.png) 

### 有什么用？

我起初接触的用法比较少，希望后续碰到能回来补充。

**Layer：**

1. 和Tag的定位类似，不过Layer似乎更常用于在渲染时、分辨一类物体。
2. 在SRP中，如果我自定义了一个Renderer Feature，我想它只对视口中的Layer值为1的物体起作用，那么我们需要在ScriptableRenderPass基类的重写的Execute函数（修改comand buffer）中，在需要传参数类型为FilteringSettings的地方，把这个参数对象的成员变量LayerMask改为1即可。

**RenderLayer：**

1. 我们可以**粗略的把Render Layer理解为一个Pass的属性**。默认情况下，通过Layer筛选过一遍要渲染的对象后，还要通过一遍物体对Pass的筛选。

   ![image-20221013202808023](Images/image-20221013202808023.png) 

   每一个Renderer组件都有一个Render Layer Mask（渲染层遮罩）的属性，本质是一个int型列表。当你想用一个Pass去渲染这个物体，Renderer组件会检查一个，你这个Pass的Render Layer的值，有没有在我的Render Layer Mask的列表中。只有在的情况，这个Renderer才会允许这个Pass去渲染这个Mesh。

   这个功能非常好用，比如我把所有可能会被描边的物体都放到一个layer中，可是对于Renderer Feature来说，一个Layer只能共同更改。也就是说，大家要么都有描边，要么都没有。这时我可以把目前不想描边的东西的Render Layer Mask（渲染层遮罩）的属性，删除掉描边Pass的Render Layer，这样这些物体就不会被渲染描边了。Render Layer Mask的值可以很轻松的动态修改。

### 总结

总之Layer 和 Render Layer就是一组分别位于渲染物体和Pass的辨识开关，只有两个开关都表示YES时物体才会被渲染。

---



## 关于URP Shader的CBUFFER

以前的批处理要求比较严格，Shader入门精要中：

> 来仔细说下批处理吧
> 分为静态批处理和动态批处理
> 静态批处理：
> 是用户手动指定的，操作方法是在Inspector面板把这个物体勾成static，就会被自动和其他同材质的东西打为一批了。这更自由，但是可能会消耗很多的内存，而且静态批处理后的物体无法移动。
> 动态批处理：
> 打开项目设置中的动态批处理后，就不需要做任何操作，Unity会自动把同一材质的物体打成一个批，而且这样批处理的物体是可以移动的。缺点是要求苛刻，顶点过多、或者光照环境稍微复杂，就无法再使用了。

总结一下就是，一般同材质的东西才能合批。

但是在URP中，放开了一些。只要物体同Shader，就有可能被合批；并且，得益于Shader变体之类的技术，一个Shader有了可以非常强大的可能。

为了使同一Shader的物体被合批，需要一些处理。本条目说的就是其中一个。

在Shader的属性声明处，使其被包裹在CBUFFER字段中，即可使同Shader、不同材质的物体被合批。

> ​	CBUFFER_START(UnityPerMaterial)
>
> ​      
>
> ​      half4 _Color;
>
> ​      half _Width;
>
> 
>
> ​      CBUFFER_END

![image-20221015201946577](Images/image-20221015201946577.png) 

但是要注意，多PassShader不可以喔。

---



## 关于软粒子

![image-20230116223031154](Images/image-20230116223031154.png) 

效果一目了然。

这么做的原理并不是关闭了深度测试，而是在片元着色器中比较渲染点的深度和深度纹理中取得的深度，若已经比深度纹理还深，说明其本来被遮挡，但此时再根据被遮挡的深度来对阿尔法值插个值即可做到这种效果。

**要注意，挡住的地方还是看不见的！这个效果只是让挡住和未挡住的地方过度平滑一些。**

这种方法对于视深的计算以及坐标系的转换的计算非常有参考价值。

[参考代码](https://blog.csdn.net/lsccsl/article/details/117926419)

[ASE中的连法](https://blog.csdn.net/qq_39574690/article/details/126448580)——注：ASE的默认粒子Shader模板中包含软粒子的算法，但是被一个全局变量限制，是一个项目设置中控制质量的变量，但是不知为何，目前我版本的Unity中没有这个选项开关。若想要开启软粒子，注释掉模板中的软粒子判断开关即可。

![image-20230116223848517](Images/image-20230116223848517.png) 



---



## 关于材质实例

如果有一个材质要用于不同的模型，而我又希望他们的参数不要同步的时候，就需要材质实例这个东西。也就是通过给与不同的模型以不同的材质实例来达到目的。

如下的melee，我希望其中一个头骨在dissolved的时候不要影响另一个，就需要材质实例

![image-20230131225637772](Images/image-20230131225637772.png) 

使用材质实例时，检查器中的材质面板会显示Instance：

![image-20230131225708991](Images/image-20230131225708991.png) 

### 分清楚Material和ShaderMaterial

二者都是Renderer组件的属性之一，二者的类型都是Material。

前者是该**物体的材质实例**，后者是**使用该Shader的材质模板**。

默认状态下，如果在代码层面不做任何修改，物体使用ShaderMaterial进行渲染，也就是说没有这个Instance。此时如果直接通过材质面板修改参数、或者修改ShaderMateria的属性，就会导致所有使用改材质的物体都被影响。

如果通过代码修改Material内的属性，则会自动创建一个材质实例，替换原来的材质，本次修改仅对该物体有效，对其他的同材质物体无效。

如果想在初始化的时候就区别开所有的材质实例，可以在Start函数中随意调用一下Material属性，只要调用就会自动生成材质实例，如下一些都是可行方式：

- New Material(meshRenderer.material)——可能会导致检查器中出现两个instance标志
- var temp_or_member_var = meshRenderer.material
- var temp_or_member_var = meshRenderer.materials[i] （多材质时）
- Function(mershRenderer.material)

### 内存泄漏问题

材质实例虽好，但是必须手动删除，否则一直存在于内存中。

使用Destroy函数即可手动释放该材质实例。

可以方便地在Mono类的OnDestory函数中写该部分内容，如下：

```c#
void OnDestroy()
{
    //Destroy the instance
    foreach (Material material in shaderMaterials){
        Destroy(material);
    }
    print("现存材质实例数量" + Resources.FindObjectsOfTypeAll(typeof(Material)).Length);
}
```



---



## 使粒子系统可以控制自定义Shader的材质的颜色

如我自己写了一个材质，但是此时粒子系统组件不能控制材质的颜色，这是因为粒子系统是通过改变顶点色来控制最终的渲染颜色。

因此，只需要在颜色计算时考虑**顶点色**，即可使粒子系统组件对材质表现出控制权。

<img src="Images/image-20230205212419240.png" alt="image-20230205212419240" style="zoom: 80%;" />![image-20230205212453583](E:/%25E6%2588%2591%25E7%259A%2584%25E5%25BE%2580%25E6%259C%259F%25E5%258A%259E%25E5%2585%25AC%25E6%2596%2587%25E4%25BB%25B6/Unity%25E8%25B5%2584%25E6%25BA%2590/%25E5%25AD%25A6%25E4%25B9%25A0/TA%25E7%259F%25A5%25E8%25AF%2586%25E9%259B%25B6%25E7%25A2%258E%25E7%25A7%25AF%25E7%25B4%25AF/Image/image-20230205212453583.png) 



---



## 关于资产预处理——Asset Post Processing

### 什么是

所有类型的资产（如模型、音频、图片）导入时都会过一遍该类型的所有的预处理，如下模型的：

![image-20230210213445574](Images/image-20230210213445574.png) 

预处理可以帮助Unity更好的理解资产，可以给资产做规范化等等。

比如我希望我项目中的所有模型，他们的Mesh的中心都是原点，那么就可以写一个资产预处理，在导入时Unity会自动通知你写的回调函数，然后执行操作更改资产。注意，这里的更改并不会更改源文件，而是让Unity对资产有额外的理解，在理解层面更改资产，源文件本身不会被改变。

### 怎么写

1. 继承 AssetPostprocessor

2. 在相关回调中编写需要处理的代码

   ![image-20230210214049010](Images/image-20230210214049010.png) 

3. 触发相应的重新导入，即可看到效果。

### 参考

[资产预处理](E:\我的往期办公文件\Unity资源\学习\供日后参考\资产预处理)

[本人写的知乎文章——关于自动中心化锚点](https://zhuanlan.zhihu.com/p/605306790)

---



---

# Part3



## 前言

泪目，Part2没用多久就殒命了。

原因是我开始工作了，为了在公司和家里方便地交流知识，只好采用线上笔记的方式。

 



## 关于插件更新的预想

2023.3.17读到一篇博客，讲了Maya插件更新功能的实现思路。[原文](https://www.cnblogs.com/meteoric_cry/p/15905357.html)

我一想，我迟早要自己编写插件更新的功能，于是按个人的疑惑问了一下ChatGPT，最后决定记下一些个人的理解。

### 什么是URL

统一资源定位符（Uniform Resource Locator）。就是一个标记文件在在服务器主机中的位置的字符串。

如：例如，http://www.example.com/index.html就是一个URL，其中http是协议，www.example.com是主机名，index.html是路径。

 

那么URL如何在更新中被使用？

URL可以指向新版本的插件，有URL，我们就可以通过代码把新版本下载用户的本地电脑中，如下Python脚本：

import urllib.request

 

url = 'http://example.com/file.txt'

save_path = 'D:\\temp\\file.txt'

 

urllib.request.urlretrieve(url, save_path)

print('文件下载成功！')

 

### 更新的整体思路

 

**在初版插件中就内置检查更新功能。**

检查更新时，将从服务器下载一个XML或Jason配置文件，用来记录版本信息和最新版本的URL。

如果用户版本不是最新的，则弹出对话框提示用户更新。

 

**下载**

用上面的代码下载最新的插件文件到本地。

 

**安装**

也可以写在更新程序中（通常更新程序和本体程序区分开来），主要是一些文件的替换和移动。

 

### 企业中运用

问了导师，说是项目组中会有自己的类似Git的项目托管，工具也会依托托管得到更新，不需要这样的传统软件更新方式。

但是了解一下也不是坏事，对吧？

 

 

 

## 关于Python装饰器和C#转义标识符

这天查Python的时候发现函数声明上一行有@……的用法，问GPT发现是函数装饰器。想起来C#也有类似的用法，比如@override，就想问这俩是不是基本一致，但发现其实根本不是一个东西。

Python中的@……叫装饰器，用于标志这个函数不是这么运行的，它被改了，在其他的地方。

C#中的@……叫做转义标识符，用于解释一些特殊的情况，这些情况在未标识时会报错。比如C#中规定，子类的函数不能和父类重名，但是虚函数打破了这个规定，是不合法的。这时需要用@override标志子类中的重名函数，则可以使这种用法合法。

 

 

 

## 空间、矩阵和变换

### 总结：

父空间坐标到子，消除父影响，左乘子空间在父空间的逆变换矩阵

子空间坐标到父，重新考虑父影响，左乘子空间在父空间的变换矩阵

如果一个矩阵能使A空间坐标转移到B空间，那么这个矩阵的逆矩阵就可以把B空间的坐标转移到A空间。

如果矩阵和坐标同空间，就是简单的变换。

如果矩阵是同空间逆矩阵，既可以理解为同空间做逆变换，也可以理解为父空间坐标到子空间，数学结果相同。

 

### 关于SMTP的个人理解

![截图.png](Images/clip_image002.gif)

![截图.png](Images/clip_image004.gif)

 

### 关于空间转换的小推导和验证

想要把子空间下的坐标转移到父空间？那不就是把子空间在父空间中的变换再应用到坐标就行吗。

如子空间有一点P（1，1）

子空间在父空间的变换矩阵为：

1 0 1

0 1 1

0 0 1

意义是向XY方向各前进一个单位。

再把这个变换应用于坐标P，得到坐标P（2，2）

这不就是P在父空间下的坐标吗？

小结：

子空间坐标到父空间坐标，给坐标应用子空间在父空间的变换即可

 

反过来，想要把父空间的坐标转移到子空间？那不就是撤销一下子空间在父空间的变换就行嘛

如有父空间一点P（1，1）

子空间在父空间的变换矩阵为：

1 0 1

0 1 1

0 0 1

它的逆变换为：

1 0 -1

0 1 -1

0 1 1

我们将逆变换应用于顶点，得到坐标（0，0）

这不就是P点在子空间下的坐标吗？

小结：

父空间坐标到子空间坐标，给坐标应用子空间到父空间的逆变换即可

![截图.png](Images/clip_image006.gif)

 

 

 

## 矩阵左乘和右乘

我一直没有理解，感觉也不太能理解。

根据GPT总结的经验：

变换应用到坐标时，坐标（列向量）右乘变换矩阵

给坐标换坐标系时，坐标左乘逆父变换矩阵

**这是错误的！**

**在图形学中，全部都是：坐标左乘变换矩阵！**

如有仿射变换矩阵M，使其作用于坐标的方式是：

P’ = MP

如果有多个变换依次作用于坐标，如依次对坐标做M1、M2变换，理论的最终坐标值是：

P‘ = M2M1P

计算过程都是从右向左，意为：P’ =（M2（M1P））

写在UnityShader中为：P‘ = mul(M2, mul(M1,P))

 

 

 

## 关于骨骼和蒙皮

主要参考文章：[CSDN](https://blog.csdn.net/n5/article/details/3105872)

 

### 骨骼的本质是什么

如果通过DCC看，骨骼不过就是一堆Transform嵌套，都包含着其在**父节点坐标系下的**Translae、Rotation和Scale的三维向量信息。

是的，骨骼的本质就是一个**普通的正交坐标系**。如果把它抽象成一个类，其中Translae、Rotation和Scale的三维向量信息是它的显性属性，为了使其能够满足上面的运算需求，它还会有很多隐性的属性。

 

### 蒙皮Mesh中，如何确定顶点在世界空间中的位置？

在普通的静态Mesh中，顶点中储存了它在模型空间下的位置，这个位置通过M矩阵可以转到世界空间下。

顶点在模型空间的坐标---<模型矩阵>--->顶点在世界空间的坐标

 

但是对于蒙皮Mesh则需要做进一步的处理：

**mesh vertex (defined in mesh space)---<BoneOffsetMatrix>--->Bone space---<BoneCombinedTransformMatrix>--->World**

**顶点在模型空间的坐标---<骨骼偏移矩阵>--->顶点在骨骼空间的坐标---<骨骼组合变换矩阵>--->顶点在世界空间下坐标**

 

### 什么是BoneOffsetMatrix矩阵？怎么算？

把顶点**从模型空间转移到骨骼空间的矩阵是骨骼偏移矩阵。**

这个矩阵保存在骨骼节点中，每个骨骼节点一个。其在DCC进行蒙皮操作时写入数据，然后就一般不再改变。

这模型空间和骨骼空间并不是什么父子关系，但是是同处世界空间下的两个坐标系，所以把顶点坐标从模型空间转移到骨骼空间时，需要：

**模型空间顶点坐标---<模型矩阵>--->世界空间---<递归地将坐标转移到指定骨骼节点>--->指定的骨骼空间的顶点坐标**

在建模规范中，往往使模型空间与世界空间重合，所以第一步常常可以省去，变为：

**世界空间顶点坐标---<递归地将坐标转移到指定骨骼节点>--->指定的骨骼空间的顶点坐标**

从上面来看，这个“<递归地将坐标转移到指定骨骼节点>”的矩阵，就是我们需要的BoneOffsetMatrix，它怎么求呢？

以下图的情况为例：

如果我想把世界空间的坐标Pw转移到b2骨骼节点空间，根据我们之前总结的经验：父到子，消除父空间影响，左乘子空间在父空间的逆变换：

Pb2 = (M3^-1 (M2^-1 (M1^-1Pw))), 根据矩阵和逆矩阵的性质，可以写成：

Pb2 = ((M1M2M3)^-1)Pw

所以，这个(M1M2M3)^-1就是所谓的BoneOffsetMatrix，这里的M123都是在创建骨骼的时候就定好的，含义是骨骼节点在其父空间下的变换。

*：M1M2M3可以理解为初始状态的BoneCombinedTransformMatrix，初始状态下，BoneOffsetMatrix就是BoneCombinedTransformMatrix的逆矩阵。

![截图.png](Images/clip_image008.jpg)

 

### 什么是BoneCombinedTransformMatrix？怎么算？

即骨骼组合变换矩阵。这个矩阵并不保存在骨骼的数据结构中，而是在需要时计算。

一个骨骼节点算出一个骨骼组合变换矩阵，在当前骨骼的上游（包括这个骨骼自己）如果任意骨骼发生变换，这个矩阵就会改变。

我们知道，骨骼的本质就是一个变换，记录它在父空间下的变换，如果是根骨骼，它的父空间为世界空间。那么从目标的骨骼节点坐标出发，一路递归考虑父节点影响，最后不就能得到世界空间下的坐标了吗？这里算出来的矩阵，不就是需要的骨骼组合变换矩阵吗？

那么根据之前总结的空间换算方法：子到父，重新考虑父影响，左乘子空间在父空间下的变换，以下图情况为例：

把bone2坐标系下的某点P的坐标转移到世界空间下的坐标的步骤就是：

**顶点在该骨骼坐标系下的坐标---<BoneCombinedTransformMatrix>--->顶点在世界坐标系下的坐标**

即：

Pw = M1M2M3Pb2

这个M1M2M3也就是需要的BoneCombinedTransformMatrix了。

![截图.png](Images/clip_image010.gif)

 

### 疑惑

我被一个问题困扰了一段时间：

既然:

**Pmesh---<((M1M2M3)^-1)>--->Bone space---<M1M2M3>--->World**

**这两个过程难道不是相互抵消了吗？因为根据逆矩阵的性质：**

((M1M2M3)^-1 X M1M2M3 = I（单位矩阵）

那这个过程其实没有对坐标做任何操作。

后来我才明白过来，第一个步骤中的M1M2M3在DCC蒙皮中就已经写入骨骼节点，以OffsetM的形式保存了，之后不会再改变；

而后一个步骤的M1M2M3已经被动画改变，而且每一帧都会更新，所以其实这两个步骤中的矩阵并不是同一个矩阵，那会使得坐标变化也是理所应当的啦。

 

### 蒙皮Mesh的渲染流程

void myDisplay(void) {

  // 清除缓存

  glClear(GL_COLOR_BUFFER_BIT);

  // 绘制原为变形Mesh，仅作调试用

  g_mesh->DrawStaticMesh(0,0,0);

  

  // 读取动画文件，更改各骨骼节点中存放的其在父空间下的变换矩阵

  animateBones();

  

  // 计算骨骼节点在世界空间下的位置，本质是计算CombineMartix

  g_boneRoot->ComputeWorldPos(0, 0, 0);

  // 遍历顶点，通过之前讲述的流程计算蒙皮后顶点的位置

  g_mesh->UpdateVertices();  

  

  // 绘制蒙皮Mesh

  g_mesh->Draw();

  

  // 绘制骨骼，调试用

  g_boneRoot->Draw();

  

  glFlush();

 

  glutSwapBuffers(); 

 

}

**读取动画，插值递归计算每一节骨骼世界坐标**

由CPU处理。

骨骼的每个节点都记录着自己在父空间下的变换，读取动画文件，将更改应用于这些变换，得到一个静态的、该骨骼在父空间下的变换矩阵。

通过递归的方法算出每一节骨骼的BCTM（递归地对子骨骼应用父骨骼的变换）

 

**蒙皮变形**

由CPU处理，输入原始mesh，遍历顶点。

先以每个顶点仅由一节骨骼影响的情况论述：

根据之前的推论：

顶点在模型空间的坐标---<骨骼偏移矩阵>--->顶点在骨骼空间的坐标---<骨骼组合变换矩阵>--->顶点在世界空间下坐标

这两个矩阵，骨骼偏移矩阵在骨骼节点中保存，骨骼组合变换矩阵在上一个步骤中也被计算出来保存在骨骼节点中。

有这两个矩阵后，就可以算出对于这一个骨骼节点，这个顶点的位置应该在哪里。

再考虑加权的情况，无非就是根据顶点中的数据（两个数组，一个保存骨骼的指针、一个保存骨骼的权重），遍历会影响它的骨骼，然后得出四个位置，再根据权值计算出平均位置，即是这个点最终的世界空间位置。

 

**渲染**

计算出的图元通过DrawCall调用GPU绘制

 

### 解答疑问：为了实现蒙皮，需要哪些条件？

l 几何体的顶点中需要保存影响它的骨骼的指针数组和权重数组

l 需要确认顶点中的指针指向有效的骨骼层次结构的骨骼节点

l 需要有一组用于控制的骨骼层次结构

l 其他基本常规要素，如模型、图形API（用于将图元打包成数据发送给GPU）、着色器等

 

 

 

## 状态模式详解

在制作工具的时候，如菜单选项这种，如果没有使用状态模式，和容易遗漏项目导致一些疑难杂症。

比如进入选项A，然后再进入选项B，此时并没有所谓的退出状态的代码，程序不会有任何操作，但是这两个操作确实实打实的叠加关系，会导致问题，而且此时一般都处于项目后期了，修改很难……

果然对于菜单选项这种东西的程序设计，还是使用状态模式为宜。

状态模式把状态也封装成类了，并且每个状态都是一个派生类，代码相对繁琐。所有考虑把这一块单独做成一个文件比较好。

![截图.png](Images/clip_image012.jpg)

 

 

 

## 配置文件、把代码写得优雅！

在工具SkinningCopyTo的开发中，我写了下面的屎山：

\# 回调：选择骨骼关联方式

def ChooseBoneCombineMode(sel):

  global skinningSetting

 

  if sel == u'根据关节位置关联'  or sel == u'使用源的骨骼'  or sel == u'复制源的骨骼':

​    skinningSetting.boneCombineMode = "closestJoint"

  elif sel == u'根据骨骼体关联' :

​    skinningSetting.boneCombineMode = "closestBone"

  elif sel == u'根据标签关联' :

​    skinningSetting.boneCombineMode = "label"

  elif sel == u'根据局部名称名字关联（仅去除命名空间部分）':

​    skinningSetting.boneCombineMode = "name"

  elif sel == u'根据骨骼层次结构关联':

​    skinningSetting.boneCombineMode = "oneToOne"

硬编码罢了，思来想去，怎么都觉得不够优雅，于是想到了使用字典：

mode_dict = {

  u'根据关节位置关联': "closestJoint",

  u'使用源的骨骼': "closestJoint",

  u'复制源的骨骼': "closestJoint",

  u'根据骨骼体关联': "closestBone",

  u'根据标签关联': "label",

  u'根据局部名称名字关联（仅去除命名空间部分）': "name",

  u'根据骨骼层次结构关联': "oneToOne"

}

 

def ChooseBoneCombineMode(sel):

  global skinningSetting

 

  if sel in mode_dict:

​    skinningSetting.boneCombineMode = mode_dict[sel]

比较优雅了，但是这个字典很碍眼，这不就是一个配置吗？最适合配置的，不是JSON文件吗？于是我向GPT了解了一下JSON：

当然可以。JSON（JavaScript Object Notation）是一种轻量级的数据交换格式，它基于JavaScript语言的一个子集，但是可以被其他编程语言如Python、Java等所支持。JSON格式非常简洁，易于阅读和编写，并且可以很好地表示各种数据类型。

JSON数据是由键值对组成的，键值对之间用逗号分隔。键必须是字符串类型，值可以是字符串、数字、布尔值、数组、对象等数据类型。JSON数据通常以文件形式存储，扩展名为 .json。

下面是一个简单的JSON示例：

{

  "name": "John Doe",

  "age": 30,

  "isMarried": false,

  "hobbies": ["reading", "swimming", "traveling"],

  "address": {

​    "street": "123 Main St",

​    "city": "New York",

​    "state": "NY",

​    "zip": "10001"

  }

}

 

这个JSON数据包含了一个人的姓名、年龄、婚姻状况、爱好和地址信息。其中，name、age、isMarried、hobbies和address均为键，对应的值分别为字符串、数字、布尔值、数组和对象。

在Python中，可以使用标准库中的json模块来解析和生成JSON数据。例如，读取上面的JSON文件可以使用如下代码：

import json

 

with open('example.json', 'r') as f:

  data = json.load(f)

 

\# data变量就是一个Python字典，可以通过键来访问对应的值

print(data['name'])

print(data['hobbies'][0])

print(data['address']['city'])

 

这样就可以将JSON数据转换成Python的字典对象，方便后续的处理。

 那用JSON保存配置不就行了么，多好：

{

  "骨骼关联配置" : {

​    "根据关节位置关联": "closestJoint",

​    "使用源的骨骼": "closestJoint",

​    "复制源的骨骼": "closestJoint",

​    "根据骨骼体关联": "closestBone",

​    "根据标签关联": "label",

​    "根据局部名称名字关联（仅去除命名空间部分）": "name",

​    "根据骨骼层次结构关联": "oneToOne"    

  }

}

然后我们去代码里读取：

import json

 

with open('config.json', 'r') as f:

  mode_dict = json.load(f)["骨骼关联配置"]

 

def ChooseBoneCombineMode(sel):

  global skinningSetting

 

  if sel in mode_dict:

​    skinningSetting.boneCombineMode = mode_dict[sel]

优雅至极！

但是，在后来我发现在定义组件的时候，我也写了屎山：

 \# 骨骼对应方式菜单

cmds.formLayout()

cmds.optionMenu("BoneCombineMode" ,label='骨骼关联方式', w=400, h=30, cc = ChooseBoneCombineMode, acc = 1)

cmds.menuItem( label=u'根据关节位置关联' )

cmds.menuItem( label=u'根据标签关联' )

cmds.menuItem( label=u'根据局部名称名字关联（仅去除命名空间部分）' )

cmds.menuItem( label=u'根据骨骼层次结构关联' )

cmds.menuItem( label=u'使用源的骨骼' )

cmds.menuItem( label=u'复制源的骨骼' )

cmds.menuItem( label=u'根据骨骼体关联' )

cmds.setParent('..')

你都写了配置文件了，为什么不从那里读取呢？

大可以改成：

 \# 骨骼对应方式菜单

cmds.formLayout()

cmds.optionMenu("BoneCombineMode" ,label='骨骼关联方式', w=400, h=30, cc = ChooseBoneCombineMode, acc = 1)

 

for key in mode_dict :

  cmds.menuItem( label = key )

 

cmds.setParent('..')

这不是清爽多了？

 

 

 

# 哈希

 

### 什么是？

哈希是一类算法，可以把**任意长度的输入转化为指定长度的字符串输出**。如：a7529dfe23（这是一个哈希值，10位16进制，可以表达最多16^10种情况）

 

### 特点是？

**高度离散性、随机性、不可逆性**

只要输入发生任意微小变化，输出的哈希值就会发生不可预测的、极大的、（理论上有规律）无规律的改变。

只能从资产到哈希值，哈希值无法反推出原资产。

 

### 怎么用？在哪里用？

1. 用作数字签名、保证数字资产的完整性、确认一个资产确实是一个资产，没有经过修改。

2. 服务器储存密码。如果你是服务器，直接把用户输入的密码储存到服务器是极其不负责的行为，因为一旦服务器被工具，用户的密码就全泄露了。使用哈希加密后，即使攻击者得到了用户的密码哈希值，也不可能通过哈希值得到用户的密码。

3. 数据库索引。和数字签名类似的，可以在服务器中通过哈希值查询到某个指定的资产。目前Stable Diffusion就是这么做的。

 

### 大概是怎么被算出来的？

基本是将**数据分块、填充、压缩**后算出来的，中间有很多参数。

常见的有SHA-1、SHA-256、MD5等。

 

### 哈希冲突

既然是一种对资产的高度抽象算法，那么是有可能会出现**多个输入对应一个输出的情况**的。这种就叫哈希冲突。

但是凭借哈希算法的高度离散性和不可预测性，哈希算法被认为是安全的。

正常使用的话，一般来说不会造成哈希冲突。

 

### 哈希碰撞

[实例](https://linux.cn/article-8238-1.html)

唉，既然哈希冲突是既定存在的事实，那么自然可以借用哈希冲突来造成攻击。

通过特殊的方法破解哈希加密，使得不同的资产得到相同的哈希值的方法，叫做哈希碰撞。

目前MD5和SHA-1均已被破解。

上面也说了，哈希值常作为签名、密码使用，这一旦被破解，各种数据安全和证书等问题，就会变得不堪一击。

 

### 在高级编程语言中的用处

哈希算法在高级编程语言中是非常常用的。

比如常见的**字典、集合，本质都是哈希表**。

在查询时，键值通过哈希算法得到哈希值，再通过哈希值寻址找到数据的位置。得益于精妙的算法，这个步骤非常快。

起初我以为字典、哈希表、键值对、都是一个东西，后来发现其实有非常微小的区别：

> 工作以后就会发现，项目中有时候用到哈希表，有时候用到字典表，这两个都是索引、值得表现形式，那么它们的区别在哪里？
>
>  以下是笔者总结的区别：
>
> 1. 字典是线程不安全的，哈希表是线程安全的，所以一般情况下单线程用字典，多线程用哈希表。
>
> 2. 字典是泛型的，数据不需要经过装箱，拆箱操作，效率更高，而哈希表不是泛型的，需要经过装箱拆箱，效率低。
>
> 3. 字典中元素的排列顺序是按照插入排序的，而哈希表不是。
>
> 4. 哈希表最大优势在于索引方式，是经过散列处理的，在数据量大的时候优势明显。

而键值对的概念比较宽，只要是把键和值映射的、一对一的映射关系，都可以被称为键值对。

 

 

# 关于Include 和 Import

import和include 的区别是？

import和include是两个不同的概念，它们在不同的编程语言中有不同的用法和含义。

在高级编程语言中，i**mport通常用于导入其他模块或库**，如Python中的import语句。而i**nclude通常用于将其他源代码文件的内容嵌入到当前文件中**，如C语言中的#include语句。

虽然它们都可以用于将其他代码包含到当前文件中，但import通常用于导入可执行代码（如函数、类等），而include通常用于包含预处理器指令（如宏定义等）和数据结构的定义。

另外，**import通常是动态的，即在运行时根据需要导入模块，而include通常是静态的，即在编译时将被包含的代码嵌入到当前文件中**。

include的处理方式非常简单，就是直接把include 的文件的内容在编译时复制到include语句的位置。

那么在执行import时，导入的是模块的源代码还是编译后的内容？

这取决于编程语言和具体的实现。 

在Python中，当你执行import语句时，Python会在sys.path路径中查找指定的模块，并将其编译为字节码文件（.pyc或.pyc文件）缓存到__pycache__目录中。下一次导入相同的模块时，Python会直接加载缓存的字节码文件，而不是重新编译源代码。因此，在Python中执行import语句实际上是导入编译后的字节码文件。

——注：这也导致Python中如果要更新引用的模块，需要处理一下缓存，或者使用重新导入命令，查阅：[关于Python的导入缓存导致的模块热更新失效问题](../Maya工具开发学习笔记/Maya工具开发学习笔记.md##关于Python的导入缓存导致的模块热更新失效问题)

在其他编程语言中，如Java，当你执行import语句时，编译器会将导入的类编译为字节码文件（.class文件），并将其打包到JAR文件或类路径中。在运行时，JVM会加载字节码文件并执行它们。因此，在Java中执行import语句实际上是导入编译后的字节码文件。

总之，大多数编程语言都会在导入模块时进行编译或转换，以便在运行时更高效地执行代码。

 



## Git的使用

因为已经用了很久的分布式版本管理了，这里只记一些不太了解的。

再你妈的见，有道。

 

### 重置参数

![截图.png](Images/clip_image014.gif) 

在TortoiseGUI中，可以在版本树中回退版本：

![截图.png](Images/clip_image016.gif) 

### 不要全部文件都托管

右键菜单中可以从库中删除这个文件，也可以通过配置把这个文件加入忽略列表中

![截图.png](Images/clip_image018.gif) 

![截图.png](Images/clip_image020.gif) 

 

### 使用分支并行开发

可以本地创建分支，然汇切换检出到新的分支。

在新分支上的修改会连同新分支的创建一起提交到云端，届时云端也会出现新的分支。

![截图.png](Images/clip_image022.gif) 

合并操作需要先切换到**“合并的目标”**这个分支，再使用合并命令指定合并的源。

 

### 变基

一图看懂好吧：

![截图.png](Images/clip_image024.gif) 

好处是可以不用再手动清理无用分支，工作树比较好看。

坏处是改变了历史，可能出现错误。

一般来说，如果是自己一个人开发的项目，可以用用变基，但如果安全性有要求，或者和别人合作的话，还是别变基了。

 

### 版本回退

本地版本回退只要选中要退的版本，右键重置就行，上面也提及了回退的参数。

![截图.png](Images/clip_image026.gif) 

但是云端的项目版本是最新的，你退了版本再推上去是推不动的，要强制覆盖：

![截图.png](Images/clip_image028.gif) 

如此，之前的所有更改就都没了，记得备份。

 

### SSH协议和HTTP协议

在一些保密程度较高、规范性较强的项目中，往往使用SSH协议：

![截图.png](Images/clip_image030.gif)

SSH通过Git的客户端生成，TortoiseGUI也可以：https://www.jianshu.com/p/1bbf5e25c912

SSH密钥分为公钥和私钥，公钥交给项目，当项目添加了你的公钥后，你可以拉取和查看项目。

当你提交时，使用你的私钥签名。只有私钥和项目中的公钥相互匹配（私钥和公钥是一对一的），你才可以提交。

总的来说，SSH就像是一个简易的账号密码，不依赖于第三方的什么服务器而已，只有被添加进项目的人才可以提交更改。

 

但是如果是自己个人的垃圾项目HTTP协议就完全够用了。。。

 

---



## lib和dll

DLL ：Dynamic Link Library 动态链接库。在程序运行时，如果运行到引用了DLL的地方，程序就会动态地加载这个DLL，读取里面的函数和变量。

LIB ： Liberal，静态链接库。其在程序编译的时候就会一起被打包到exe中。

他们都是编译后的二进制文件。

由于他们的链接特性不同，打包后的主程序可以脱离Lib运行，但是不能脱离DLL运行。

在IDE中，可以设置Lib和Dll的路径，来识别里面的函数和变量等。这样就可以正确的Import或者include了。



---



## C#拆分类的方式

有时候编写的类里面属性和一些比较杂的方法太多了，不方便查看和编写，此时就可以使用：partial关键字来修饰这个类，被修饰的类会和与其重名的类合并为一个完整的类。

一段看懂：

在文件Person.cs中定义一个类Person：

```c#
public partial class Person
{
    public string FirstName { get; set; }
    public string LastName { get; set; }
}
```

在文件PersonDetails.cs中定义同一个类Person的另一部分：

```c#
public partial class Person
{
    public int Age { get; set; }
    public string Email { get; set; }
}
```

优缺点：

使用partial关键字的优点包括：

1. 增加代码可读性和维护性，通过将一个类或方法拆分为多个partial类或partial方法，使得代码更易于理解和修改。
2. 支持**多个开发者同时对同一个类或方法进行修改**，每个开发者可以在自己的partial类或partial方法中进行修改，避免了代码冲突。
3. 可以将自动生成的代码和手写的代码分离，**方便代码生成工具和手写代码的管理**。



使用partial关键字的缺点包括：

1. 增加了代码的复杂性，需要开发者更加谨慎地进行设计和维护。
2. 可能会导致代码逻辑不连贯，需要开发者进行额外的工作来确保partial类或partial方法在合并后的代码中具有正确的顺序。
3. 可能会导致代码的**执行效率降低**，因为partial类或partial方法会增加额外的开销。

 

---



## 使用IDE的重构功能

选中代码块后右键菜单中选重构，就能弹出重构菜单：

![image-20230518145408106](Images/image-20230518145408106.png) 



### #if

[预处理器指令](##预处理器指令)



### #region

单词的意思是区域。

可以像方法或者类那样，在IDE中折叠这一块的代码



### #checked

由Checked block指令生成，会包裹选中的代码。

`checked{}` 语句块是 C# 中的一种语法结构，用于在代码块中启用**整数算术运算的溢出检查**。在 `checked{}` 语句块中进行的所有整数算术运算都会进行溢出检查。如果检测到溢出，将引发 `System.OverflowException` 异常。



### 提取方法

这个很好用。选中一个代码块，可以自动把它作为函数打包。



---



## 预处理器指令

在编译时，编译器可以识别代码中的预处理器指令，然后对代码做出一些操作。

常用的有：

1. `#include`: 用于包含其他源文件或头文件。可以使用`#include`指令将一个源文件中定义的函数或变量包含到另一个源文件中。[关于Include 和 Import](##关于Include 和 Import)
2. `#define`: 用于定义宏。可以使用`#define`指令定义一个标识符和其对应的值或代码片段，然后在代码中使用该标识符作为代替。
3. `#ifdef`和`#ifndef`: 用于条件编译。`#ifdef`指令用于检查一个标识符是否已经定义，如果定义了则编译后面的代码，否则忽略。`#ifndef`指令则相反，用于检查一个标识符是否未定义，如果未定义则编译后面的代码。
4. `#pragma`: 用于向编译器发送特定的命令或指令。`#pragma`指令通常用于控制编译器的行为，例如设置警告级别、关闭某些警告或优化代码。
5. `#error`: 用于在编译时生成一个错误消息。可以使用`#error`指令在编译过程中生成一个错误消息，以提醒程序员必须解决的问题。

以上预处理器操作，根据语言的不同，也会有写法上的不同，如C#中是#if。



---



# C# 静态查找、匹配、读取文件——UnityEditor

需要注意，这里的方法使用了AssetDatabase，其属于UnityEditor命名空间下的类，这个类只会在Editor模式下起作用。

[Maya笔记——通配符](../Maya工具开发学习笔记/Maya工具开发学习笔记.md###通配符)

制作工具时，往往需要在脚本中读取本地的资产。

```c#
cubemap = AssetDatabase.LoadAssetAtPath<Cubemap>("Assets/MyFolder/myCubemap.cubemap");
```

但是这不太支持通配符，所以只能先获取匹配上的路径列表，再对列表的内容进行访问：

```c#
// 查找以 "0_" 开头的文件
string[] files = Directory.GetFiles(folderPath, "0_*");

foreach (string file in files)
{
    // 加载文件
    Object obj = AssetDatabase.LoadAssetAtPath(file, typeof(Cubemap));

    // 将加载的对象转换为 Cubemap 类型
    Cubemap cubemap = obj as Cubemap;

    // 处理 Cubemap
    // ...
}
```

简易的匹配操作可以使用通配符，而如果通配符无法完成任务，则可能需要使用正则表达式：[正则表达式](#正则表达式)



---



# 利用Unity进行对于图片文件的读取、写入和导出

工作中需要把CubeMap的一面导出为普通的图片格式，但是这方面我完全没有了解过。

这其中也包含了修改文件的工作流：

**从文件中读取信息 → 处理读取出的数据 → 将处理后的数据重新写入文件**



结合ChatGPT和Copilot，得到了下列的代码：

```c#
private void GetCubeMapSide(CubemapFace face){
    int size = iterationCubeMap.width;
    Texture2D tex = new Texture2D(size, size, TextureFormat.RGB24, false);
    Color[] colors = iterationCubeMap.GetPixels(face);
    tex.SetPixels(colors);
    tex.Apply();
    
    //编码导出主要是下面的部分
    byte[] bytes = tex.EncodeToPNG();
    string path = "Assets/0_在研/CubeMaps/1_" + face.ToString() + ".png";
    File.WriteAllBytes(path, bytes);
    AssetDatabase.Refresh();
}
```

 因为对于我来说是全新的领域，所以想要记一下。



## Texture2D类

其代表Unity内的纹理类型。上述代码通过长宽、编码格式和是否使用MipMap作为参数初始化了这个对象。



## TextureFormat

Format直译是格式，但是不太好理解。

这里的RGB24指的是RGB3个通道，每个通道8位（bit）。

在百人计划中，我们了解过这个编码格式：[53：纹理压缩](../百人计划学习笔记/百人计划学习笔记.md##53：纹理压缩)

RGB24是非压缩格式，适合让CPU处理，而不适合让GPU进行读取。



## tex.Apply()

tex.Apply() 方法用于将设置了颜色的 Texture2D 对象提交到 GPU 进行渲染，这样可以确保修改后的纹理可以立即在场景中显示出来。如果不调用此方法，修改的纹理将不会被更新并显示在场景中。



## tex.EncodeToxx()

Texture2D类的方法，将Texture2D对象编码为对应格式所需要的byte数组

![image-20230519174031149](Images/image-20230519174031149.png) 



## File.WriteAllBytes(path, bytes)

将字节数组内容写到指定路径的指定文件。



---



# 静态（类型）语言和动态（类型）语言、强类型性和弱类型性

[参考文献](http://c.biancheng.net/view/8803.html)、[参考文献2](https://zhuanlan.zhihu.com/p/109803872)、[参考文献3](https://developer.aliyun.com/article/646209)

静态（动态）语言用于区分高级编程语言，一种语言只可能是静态或者动态语言。

强类型性和弱类型性是语言的一种性质，可以说一种语言有强类型性或者弱类型性。

一般来说，静态语言具有强类型性，动态语言具有弱类型性。

了解这两种语言的特性可以帮助快速上手一些陌生的语言。



## 静态语言

本质上，当一种语言在编译时就决定了变量的类型，那么可以说这种语言是静态语言。



**静态语言的特点**

1. 变量**必须在使用之前声明其类型**。
2. 变量的类型在编译时就已确定，**不允许在运行时改变**。
3. 静态类型语言具有**更好的类型检查**，可以在编译时发现类型错误，减少运行时错误。
4. 静态类型语言通常需要**更多的代码**来定义类型和声明变量，但可以**提高代码的可读性和可维护性**。
5. **编译器可以进行更多的优化**，因为它们知道代码中的类型信息。
6. 静态类型语言比动态类型语言**更适合大型项目和团队开发**，因为它们提供了更强的类型安全性和更好的文档支持。

 

##  动态语言

当变量的类型来自赋予给它的值而不是变量的定义时，可以说这种语言是动态语言。



**动态语言的特点**

1. 变量的**类型在运行时动态确定**，**允许在运行时改变变量的类型**。
2. 动态类型语言通常需要**更少的代码**来定义类型和声明变量，但可能会**降低代码的可读性和可维护性**。
3. 动态类型语言在编写代码时**更加灵活**，因为它们不需要在编写代码时考虑类型信息。
4. 动态类型语言通常比静态类型语言**更容易学习和使用**，因为它们不需要在编写代码时考虑类型信息。
5. 动态类型语言通常比静态类型语言更**适合快速原型开发和小型项目**，因为它们提供了更高的灵活性和快速迭代的能力。
6. 动态类型语言在**运行时可能会出现类型错误**，因为类型检查是在运行时进行的，而不是在编译时进行的。

 

## 强类型性

类型性的强弱体现在对于**类型转换的严格程度**。

强类型性的语言严格管控类型转换，比如C#中无法用int + string。

> 这就是强类型语言的典型特征，它们不会处理与类型定义明显矛盾的运算，而是把它标记为一个问题，并作为错误抛出。通常人们认为 C/C++、Java、C#、Python、Go 都是强类型语言，它们都不允许上述代码中的行为。

话虽这么说，但是在C++（C#中也有类似的窗口）中，开发者可以通过重写操作符等方式主动地使得类型转换变得宽松。



## 弱类型性

弱类型性的语言对于类型转换相对宽松且自动，但也带来了一定的不可控性。

比如在Python中，可以用int型加上string， 5 + ‘5’ == ‘55’.

> 和强类型语言不一样，当我们执行一些与类型定义不匹配的运算时，**弱类型语言尝试提供帮助**，它可能会**临时转换值的类型**，让它符合当前运算。
>
> 类型系统的“强/弱”指的是当编程语言遇到与类型定义不匹配的运算时，**尝试猜测或者转换的力度**/程序。它不是一条明确的界限，而是一个范围。
>
> - 强类型语言在遇到与类型定义明显矛盾的运算时，一般会当做一种语法错误，而不会尝试对值的类型进行转换。
> - 弱类型语言恰好相反，会猜测程序员的意图，并对其中一些值的类型进行转换，以让程序继续执行。
>
> 强/弱类型是一个相对概念，将两种语言放在一起对比时，才更容易发现孰强孰弱。



## 常见语言分类

![image-20230526174844950](Images/image-20230526174844950.png) 



---



# 关于UnityEditor下的API导致的打包失败问题

按照规范，使用了UnityEditorAPI的脚本都应该放置到Assets/Editor文件夹下。

如果不，使用了UnityEditorAPI的脚本也会在Build的时候被编译，然而编译的时候，**UnityEditor的dll是不会参与编译的**，这将导致Build报错找不到该API，最终**导致打包失败。**

解决方法有二：

1. 好好**按照规范**把使用了UnityEditorAPI的脚本放到对应的文件夹下。
2. 把脚本使用**`#if UNITY_EDITOR`的预处理命令包裹**，这样在编译的时候实际不会编译这一段代码，也就不会报错导致编译失败了。



---



# 使用路径

有时候编写工具需要大量使用路径，这时候活用字符串的API、通配符和正则表达式等，可以大幅优化和简化路径的使用流程。

之后会在这个板块不断更新关于路径的内容。



## 相对路径

Unity中本身就使用了相对路径，一般有Asset、Resource等的锚点供开发者使用。

但是，在大型项目中文件夹的前缀往往很长，这时候每次搞路径都很痛苦，所以可以这样：

定义一个路径前缀：

`private string pathPrefix = "Assets/Scene/***_scene/***_bake/*****/";`

也可以不手写路径前缀，而是直接通过这个对象本身的位置作为前缀：

`pathPrefix = AssetDatabase.GetAssetPath(this);`

在之后使用路径的时候，就可以非常愉快地写了：

`probeCubemap =  AssetDatabase.LoadAssetAtPath<Cubemap>(pathPrefix + "CubeMaps/****.exr");`

整体思路很像大多数DCC的“项目”这个概念。



## 使用通配符或者正则表达式匹配

先复习一下什么是通配符：[Maya笔记——通配符](../Maya工具开发学习笔记/Maya工具开发学习笔记.md###通配符)

在开发中，有时候想匹配很多文件，或者说想要更名自由一点，即使名字有不同也能正确地匹配上，这时候就需要进行**匹配操作。**

简易的匹配操作可以使用通配符进行匹配，如果匹配规则比较复杂，则可能需要使用[正则表达式](#正则表达式)。使用方法如：[C# 查找、匹配、读取文件](#C# 查找、匹配、读取文件)



---



# 正则表达式

正则表达式是一种强大的匹配机制，其比[通配符](../Maya工具开发学习笔记/Maya工具开发学习笔记.md###通配符)更加复杂，但也能处理更加复杂的情况。



**以下是一些C#中常用的正则表达式相关语句：**

创建正则表达式对象：

```
Regex regex = new Regex(pattern);
```

检查字符串是否匹配正则表达式：

```
bool isMatch = regex.IsMatch(input);
```

获取第一个匹配项：

```
Match match = regex.Match(input);
```

获取所有匹配项：

```
MatchCollection matches = regex.Matches(input);
```

替换匹配项：

```
string result = regex.Replace(input, replacement);
```

获取匹配项的位置和长度：

```
int index = match.Index;
int length = match.Length;
```

获取匹配项的值：

```
string value = match.Value;
```

在正则表达式中使用字符类：

```
string pattern = "[aeiou]"; // 匹配任何一个元音字母
```

在正则表达式中使用量词：

```
string pattern = "a{2,4}"; // 匹配2到4个连续的字母a
```

在正则表达式中使用分组：

```
string pattern = "(ab)+"; // 匹配一个或多个连续的ab
```



**关于正则表达式的编写：**

![常用语法](Images/常用语法.png) 



**关于正则表达式的验证和测试：**

https://regex101.com/r/lzwFoS/1



**我使用正则表达式的实例：**

[FBX动画自动切分工具](../供日后参考/正则表达式)



**参考视频：**

[10分钟搞懂正则表达式](https://www.bilibili.com/video/BV1da4y1p7iZ/?spm_id_from=333.337.search-card.all.click&vd_source=9a5fef48671479d11a7dd5cdf12ca388)



---



# Resources类，动态加载和管理资源

不同于AssetDatabase，Resources是属于UnityEngine下的类，其可以被Build。

Resources常用于GamePlay中对资产的动态加载、卸载、异步加载等。和静态的工具加载资产完全是两回事。

> 以下是一些常用的Resources类相关的API：
>
> 1. Resources.Load：用于从Resources文件夹中加载资源，可以加载预制体、材质、纹理、音频等。
> 2. Resources.LoadAsync：异步加载资源，可以避免在加载资源时卡住游戏。
> 3. Resources.UnloadUnusedAssets：用于卸载没有被引用的资源，可以释放内存空间。
> 4. Resources.FindObjectsOfTypeAll：查找场景中所有的对象，并返回一个包含所有对象的数组。
> 5. Resources.GetBuiltinResource：获取Unity内置资源，如字体、图片等。
> 6. Resources.LoadAll：一次性加载指定文件夹下的所有资源，返回一个包含所有资源的数组。
>
> 需要注意的是，由于Resources文件夹中的资源会被打包到游戏中，因此需要谨慎使用，避免资源过多导致游戏体积过大。同时，建议使用Asset Bundle来管理游戏资源，因为它具有更好的扩展性和灵活性。



---



# 拉姆达表达式

拉姆达表达式常用于**创建匿名函数对象**。

拉姆达表达式在某些事件的添加、简短函数定义等情况下用处很大，可以使代码简洁易读。

比如在Dotween中为tweening动画中**添加结束事件**：

```
void Start()
{
    transform.DOMoveX(10, 1).OnComplete(
    	() => Debug.Log("Tweening animation completed.")
    );
}
```



也可以用作**简短函数的定义**，比如只有一行的函数：

 `private void ChangeMatRatio() => ballInScene.GetComponent<MeshRenderer>().sharedMaterial.SetFloat("_RefractRatio", mat_ratio);`



**拉姆达表达式的组成：**

> Lambda表达式由以下几部分组成：
>
> ```
> (parameters) => expression
> ```
>
> 其中，每个部分的含义如下：
>
> - `parameters`：表示Lambda表达式的参数列表，可以是一个或多个参数，如果没有参数，可以省略括号。参数的类型可以显式指定，也可以由编译器自动推断。
> - `=>`：称为Lambda运算符，表示“goes to”，它将参数列表和表达式分开。
> - `expression`：表示Lambda表达式的主体，可以是单个语句或一系列语句，可以使用花括号括起来来表示多个语句。
>
> Lambda表达式通常用于创建委托对象，可以将其视为一个匿名方法。在C#中，Lambda表达式可以用于各种情况，例如LINQ查询、事件处理程序和异步编程等。



---



# 事件系统

高级编程语言中常用事件系统，接下来我们以C#为例。

**什么是事件系统？**

从本质来说，**事件是一系列具有相同参数和返回值类型的函数集合**。

（事件中的函数基本是不返回值的，如果硬要返回一些什么东西，考虑使用out关键字或者其他方法）

一旦触发事件，**事件会以接收到的参数执行每一个其内的函数**。

**事件内的函数可以动态地加减**。



**事件系统的应用场合**

> 以下是一些事件系统的应用场合：
>
> 1. GUI编程：在图形用户界面编程中，事件系统被用来**处理用户输入和其他系统事件，例如鼠标点击、键盘输入、窗口关闭等等**。
> 2. 游戏编程：在游戏编程中，事件系统被用来处理各种游戏事件，例如**角色移动、碰撞检测、攻击事件等等**。
> 3. 网络编程：在网络编程中，事件系统被用来处理各种网络事件，例如**连接、断开、收到数据包等等**。
> 4. 服务器编程：在服务器编程中，事件系统被用来处理各种服务器事件，例如**客户端连接、请求处理、错误处理等等**。
> 5. 框架编程：在各种框架编程中，事件系统被用来处理各种框架事件，例如应用**程序启动、关闭、组件加载、卸载等等**。
>
> 总之，事件系统可以应用于任何需要处理事件的场合，它可以帮助程序员更好地组织代码，提高代码的复用性和可维护性。

事件的名称往往是“OnXXXX”的形式，表示当XXX时，运行这个事件，而事件内有什么委托？取决于运行的情况。



**事件系统的简单实例：**

```c#
using UnityEngine;
using System;

public class Player : MonoBehaviour
{
    // 定义一个自定义委托类型，用于处理玩家死亡事件。
    // 所谓的委托类型，类似于一个“函数模板”，使用这个模板的函数必须拥有于模板相同的返回值和参数列表
    public delegate void PlayerDeathHandler(Player player, int score);

    // 定义一个事件，用于通知其他脚本玩家已经死亡
    public event PlayerDeathHandler OnPlayerDeath;
    
    // 定义一个匿名函数，并将其赋值给一个PlayerDeathHandler委托类型的函数对象。
    public PlayerDeathHandler deathFunc = (player, score) => {}

    private void Update()
    {
        // 如果玩家死亡，触发事件通知其他脚本
        if (isDead)
        {
            // 将方法注册到事件
            OnPlayerDeath += deathFunc;
            // 将玩家和分数作为事件参数传递给已注册的委托
            OnPlayerDeath?.Invoke(this, score);
            // 这里的？是null条件运算符，只有当OnPlayerDeath事件内有委托的时候才会Invoke，否则不Invoke。这样可以避免一些错误
        }
    }
}
```

注意，添加进event对象的函数对象是会重复的，意味着重复添加一个函数进入event，那么这个函数会在一次Invoke中被执行多遍。



**使用Action和Func类型**

看了上面的示例，是不是觉得**自己定义委托类型还挺麻烦的**？

为了解决这些麻烦，Unity预置了一些委托类型，**Action和Func是两类常用的预置委托模板。**

> 在Unity中，Action类是一个预定义的委托类型，用于表示一个**不返回值的方法**。它可以用于将方法作为参数传递给其他方法，或者在事件处理中注册方法。Action类可以有**最多四个参数**，如果需要更多的参数，则可以使用带有泛型参数的Action类。例如，**Action<int>表示一个带有一个整数参数的方法**，而**Action<int, float, string, bool>表示一个带有四个参数的方法**，分别为整数、浮点数、字符串和布尔值。

> Func类与Action类非常相似，但它可以表示带有返回值的方法，并且在定义时需要指定返回值类型。例如，**Func<int>表示一个返回整数类型的方法**，而**Func<int, float, string, bool>表示一个带有三个参数并返回布尔值类型**的方法。

这样我们就可以使用Action去定义委托类型的对象，使其加入事件了。



---



# 翻转纹理

看似简单的功能，没有GPT和Copilot我还真写（抄）不出来捏：

其中colors是从图片读取出来的信息： `Color[] colors = cm.GetPixels(face); `

```c#
// 左右翻转
for (int i = 0; i < size / 2; i++)
{
    for (int j = 0; j < size; j++)
    {
        Color temp = colors[i * size + j];
        colors[i * size + j] = colors[(size - 1 - i) * size + j];
        colors[(size - 1 - i) * size + j] = temp;
    }
}
// 上下翻转
for (int i = 0; i < size; i++)
{
    for (int j = 0; j < size / 2; j++)
    {
        Color temp = colors[i * size + j];
        colors[i * size + j] = colors[i * size + size - 1 - j];
        colors[i * size + size - 1 - j] = temp;
    }
}
```



---



# 关于ImportSetting、资产和Meta文件（元数据）

导入项目的所有资产（甚至是文件夹）都有一个自己专属的**Meta文件**，这个文件叫做**元数据**，用于**告诉Unity如何解释这个资产**。

![image-20230605170023436](Images/image-20230605170023436.png) 

一般来说，用户在**检查器上的修改不会修改到资产的源文件上**，**而是修改到元数据上**，让Unity对这个资产文件的理解发生改变。

注意，这个资产的名字后就带了**“Import Setting”，它的本质就是元数据**，其实我们在直接修改的只有元数据。

![image-20230605170133536](Images/image-20230605170133536.png) 

最后在**打包时，Unity也根据这些资产的元数据去处理这些资产，处理完后再打入包体中。**

有些资产是不显示所谓的Import Settings，比如材质（mat）文件就不显示，大概是因为不需要显示。（虽然它有meta文件）

![image-20230605170444056](Images/image-20230605170444056.png) 



有时我们会希望通过代码修改资产的Importsetting，这时需要通过各种Importer类来实现，如：

```c#
TextureImporter importer = AssetImporter.GetAtPath(path) as TextureImporter;
importer.isReadable = true;
importer.sRGBTexture = false;
// 重新导入以刷新资产
AssetDatabase.ImportAsset(path, ImportAssetOptions.ForceUpdate);
```



**区分资产读取和ImportSetting控制**

如果想读取一个目录下的资产，我们会使用：

 `iterationCubeMap = AssetDatabase.LoadAssetAtPath<Cubemap>(path);`

我们将会得到一个很灵活的Cubemap对象。



但如果是想修改它的ImportSetting，我们需要使用：

`AssetImporter.GetAtPath(path) as TextureImporter;`

我们将得到一个对应类型的Importer对象，而不是资产类型。



这二者完全不互通，无法通过资产获取它的Import，也无法通过Importer获取资产。



---



# 关于Blit

不知道何时受什么影响，**我一直以为URP中不支持Graphc.Blit**。

但后来发现**其实也是支持的**，只是需要一点点的特殊处理，顺其自然写就行了。

顺便贴一下Shader入门精要的经典代码：Blit循环（Build-in）

```c#
RenderTexture buffer0 = RenderTexture.GetTemporary(rtW, rtH, 0);
buffer0.filterMode = FilterMode.Bilinear;

Graphics.Blit(source, buffer0);

for (int i = 0; i < times; i++) {
    blitMaterial.SetFloat("_BlurSize", 1.0f + i * blurSpread);

    RenderTexture buffer1 = RenderTexture.GetTemporary(rtW, rtH, 0);

    // Render the vertical pass
    Graphics.Blit(buffer0, buffer1, blitMaterial, 0);

    RenderTexture.ReleaseTemporary(buffer0);
    buffer0 = buffer1;
    buffer1 = RenderTexture.GetTemporary(rtW, rtH, 0);

    // Render the horizontal pass
    Graphics.Blit(buffer0, buffer1, blitMaterial, 1);

    RenderTexture.ReleaseTemporary(buffer0);
    buffer0 = buffer1;
}
```



---



# 关于Shader变体

书到用时方恨少！

> 在Unity中，Shader变体是**根据不同的平台、渲染管线、材质属性和宏定义等因素生成的一组Shader程序**。这些变体将在**运行时自动编译并使用**，以确保在**不同的环境中具有最佳的性能和质量**。Shader变体的生成是通过Unity的**Shader编译器和预处理器进行**的，可以通过**手动设置Shader的编译选项和宏定义**来控制变体的生成。

按我的理解来说，Shader变体就是在Shder代码中添加类似C#的预处理命令，在编译Shder的时候如果读到这些预处理命令，就会编译出两个Shader文件，分别对应着这个开关的两种结果。

如果一个Shader中有N个if预处理，那么这个Shader最少会产生2^N个Shader变体。

变体技术以前常用在做渲染API和设备的区分，但是现在也有很多新的不太正确的用途。比如制作所谓的“超级Shader”（Shader内含大量常用功能，通过宏控制其开关）。



## 如何让Shader产生变体？

> 在Unity中，可以通过在Shader文件中添**加#pragma指令来修改编译选项**。以下是一些常用的编译选项：
>
> 1. \#pragma vertex函数名：指定顶点着色器函数。
> 2. \#pragma fragment函数名：指定像素着色器函数。
> 3. \#pragma target指令：指定着色器的目标平台和渲染管线。例如，#pragma target 3.0表示使用DirectX 9渲染管线。
> 4. \#pragma multi_compile指令：指定要编译的宏定义列表，用于生成不同的Shader变体。例如，#pragma multi_compile _DEBUG _RELEASE表示生成两个变体，一个用于调试，一个用于发布。
> 5. \#pragma shader_feature指令：指定要编译的Shader功能列表，用于生成不同的Shader变体。例如，#pragma shader_feature _ALPHATEST_ON表示生成支持Alpha测试的Shader变体。



在编译命令中，比较常用的应该是这个：

> 当使用 **#pragma shader_feature 指令**时，Unity 会为每个指定的特性生成一个 shader 变体。如果特定特性在 Material 中启用，则使用支持该特性的 shader 变体。
>
> 以下是一个 #pragma shader_feature 指令的示例：
>
> ```
> #pragma shader_feature _ALPHATEST_ON
> #pragma shader_feature _SPECULARHIGHLIGHTS_OFF
> ```
>
> 这个示例中，#pragma shader_feature 指令指定了两个特性：_ALPHATEST_ON 和 _SPECULARHIGHLIGHTS_OFF。如果这两个特性在 Material 中启用，则 Unity 会生成支持这两个特性的 shader 变体。
>
> 可以在 Shader 中使用这些特性来编写条件代码。例如：
>
> ```
> #if _ALPHATEST_ON
>     clip(_AlphaClip);
> #endif
> 
> #if _SPECULARHIGHLIGHTS_OFF
>     half3 spec = 0;
> #else
>     half3 spec = _SpecColor.rgb * _Specular * pow(saturate(dot(reflect(-_LightDir, _WorldNormal), _WorldViewDir)), _Shininess);
> #endif
> ```
>
> 在这个示例中，如果 _ALPHATEST_ON 特性启用，则执行 clip(_AlphaClip); 来实现 alpha testing。如果 _SPECULARHIGHLIGHTS_OFF 特性启用，则将 spec 变量设置为 0，否则使用标准的 Phong 镜面反射模型来计算 spec 变量。
>
> 在这种方式下，使用 #pragma shader_feature 指令可以有效地减少 shader 变体的数量，从而提高性能。



在ASE中，可以使**用Static Switch节点做到这件事**：

![image-20230719190234409](Images/image-20230719190234409.png) 



## Shader变体是如何工作的？

我们知道，Unity项目其实是源码级别的东西，它需要经过编译后才能运行。

Shader则是**在编译的过程中生成不同的变体**的。我们在Shader中使用编译命令生成变体，它就会在项目打包的时候根据各个编译时常量来分化出很多变体，并检出需要的变体打入包体中。

这就是为什么Runtime中如果使用Shader变体，常常会看到蓝色的部分，这部分就是Shader变体的部分，在Runtime模式下变体还没来得及被编译，所以暂时显示为蓝色。而一旦出包，Shader变体的编译工作在项目打包过程中就已经全部完成，就不会再有蓝色的部分被显示出来了。



## 使用变体的优缺点



> 在Unity中，使用Shader变体的优点和缺点如下：
>
> 优点：
>
> 1. 性能优化：Shader变体允许根据不同的渲染需求生成多个变体，以适应不同的硬件和平台。这可以最大限度地减少不必要的计算和内存开销，提高渲染性能。
> 2. 灵活性：Shader变体使开发者能够根据需要定制和优化渲染管线。通过调整变体的参数和功能，可以实现各种视觉效果和渲染技术。
> 3. 跨平台兼容性：Shader变体可以根据目标平台进行编译和优化，以确保在不同的设备和操作系统上都能正确运行和呈现一致的渲染效果。
>
> 缺点：
>
> 1. 内存占用：每个Shader变体都需要占用一定的内存空间。如果变体过多或者组合复杂，可能会导致内存占用增加，尤其是在移动设备等资源受限的平台上。
> 2. 编译时间：生成和编译Shader变体可能需要一定的时间，特别是在首次构建项目或者更改Shader时。对于大型项目或频繁迭代的开发过程，这可能会增加开发时间。
> 3. 维护复杂性：使用Shader变体时，需要管理和维护多个变体的参数和功能。如果变体过多或者代码结构不清晰，可能会增加开发者的工作量和复杂性。
>
> 综上所述，Shader变体在性能优化和灵活性方面具有优势，但也需要权衡内存占用、编译时间和维护复杂性等因素。



---









